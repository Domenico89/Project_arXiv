{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will explain how the model was trained and how its evaluation could be performed. The code contained here is essentially the same that can be found in train_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import shuffle\n",
    "#utils module can be found in src folder\n",
    "from utils import Config, strip_extension, read_clean, get_y\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "\n",
    "n_jobs=multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training the model let's see what an article looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EUROPEAN ORGANISATION FOR NUCLEAR RESEARCH (CERN)\n",
      "\n",
      "arXiv:1402.7029v3 [hep-ex] 6 May 2014\n",
      "\n",
      "CERN-PH-EP-2014-019\n",
      "Submitted to: JHEP\n",
      "\n",
      "Search for direct production of charginos and neutralinos in\n",
      "events with three leptons and missing transverse momentum in\n",
      "√\n",
      "s = 8 TeV pp collisions with the ATLAS detector\n",
      "\n",
      "The ATLAS Collaboration\n",
      "\n",
      "Abstract\n",
      "A search for the direct production of charginos and neutralinos in final states with three leptons\n",
      "√\n",
      "and missing transverse momentum is presented. The analysis is based on 20.3 fb−1 of s = 8 TeV\n",
      "proton–proton collision data delivered by the Large Hadron Collider and recorded with the ATLAS\n",
      "detector. Observations are consistent with the Standard Model expectations and limits are set in Rparity-conserving phenomenological Minimal Supersymmetric Standard Models and in simplified supersymmetric models, significantly extending previous results. For simplified supersymmetric models\n",
      "±\n",
      "0\n",
      "of direct chargino (χ̃1 ) and next-to-lightest neutralino (χ̃2 ) production \n"
     ]
    }
   ],
   "source": [
    "txts = os.listdir(Config.txt_db)\n",
    "idxs=[strip_extension(txt) for txt in txts]\n",
    "\n",
    "with open(os.path.join(Config.txt_db,txts[0]),'r') as file:\n",
    "    article=file.read()\n",
    "print(article[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen at the beginning of each article, arXiv.org places the title, the id and the class of the paper. Since we are trying to write an application that determines the class of an input article, it is reasonable to remove these information from the articles.  It is clear that we should remove the class as it might be possible that the model would pick up the classes and therefore classify the papers based on it. We remove the article name because there might be other articles referencing the paper, which might help classifying it, while the model is intended to be used for papers that would be completely new. \n",
    "\n",
    "This justifies the definition of function utils.read_clean(), that cleans the articles in the database before feeding them to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the TFIDF vectorizer.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='replace',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=60000,\n",
       "                min_df=2, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words='english', strip_accents='unicode',\n",
       "                sublinear_tf=True,\n",
       "                token_pattern='(?u)\\\\b[a-zA-Z_][a-zA-Z0-9_]+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txts = os.listdir(Config.txt_db)\n",
    "idxs=[strip_extension(txt) for txt in txts]\n",
    "\n",
    "max_features=60000\n",
    "\n",
    "tfidf = TfidfVectorizer(input='content',encoding='utf-8', decode_error='replace', \n",
    "             strip_accents='unicode',lowercase=True, analyzer='word', stop_words='english', \n",
    "             token_pattern=r'(?u)\\b[a-zA-Z_][a-zA-Z0-9_]+\\b', ngram_range=(1, 2),\n",
    "             max_features = max_features, norm='l2', use_idf=True, smooth_idf=True, \n",
    "             sublinear_tf=True, max_df=1.0, min_df=2)\n",
    "\n",
    "#hard copy of the list of papers\n",
    "train_txt_paths = list(idxs) \n",
    "#shuffle the list of articles and crop it\n",
    "shuffle(train_txt_paths) \n",
    "max_train=70000\n",
    "train_txt_paths = train_txt_paths[:min(len(train_txt_paths), max_train)]\n",
    "#prepare the corpus\n",
    "train_corpus = read_clean(train_txt_paths)\n",
    "#fit the model\n",
    "print('Training the TFIDF vectorizer.')\n",
    "tfidf.fit(train_corpus)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have a look at the features learned by the model look like and save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['slow', 'quantum', 'thermalization', 'body', 'revivals', 'mixed', 'phase', 'space', 'jan', 'ist', 'austria', 'campus', 'school', 'physics', 'astronomy', 'university', 'leeds', 'ls2', 'united', 'kingdom', 'department', 'theoretical', 'geneva', 'switzerland', 'dated', 'january', 'relaxation', 'systems', 'strongly', 'depend', 'initial', 'state', 'semiclassical', 'regions', 'chaotic', 'motion', 'coexist', 'regular', 'islands', 'recent', 'years', 'effort', 'understand', 'process', 'interacting', 'lack', 'obvious', 'limit', 'time', 'dependent', 'variational', 'principle', 'allows', 'systematically', 'derive', 'effective', 'classical', 'nonlinear', 'dynamical', 'projecting', 'unitary', 'dynamics', 'manifold', 'weakly', 'entangled', 'states', 'demonstrate', 'generally', 'possess', 'errors', 'small', 'leaves', 'footprint', 'exact', 'model', 'example', 'initialized', 'belonging', 'stable', 'periodic', 'orbit', 'surrounding', 'region', 'exhibits', 'persistent', 'proof', 'identify', 'new', 'types', 'scars', 'lead', 'long', 'oscillations', 'rydberg', 'atoms', 'dimensions', 'intriguingly', 'rise', 'robust', 'typically', 'hand', 'large', 'tilted', 'field', 'ising', 'initializing', 'leads', 'surprising', 'slowdown', 'work', 'establishes', 'method', 'identifying', 'anomalous', 'arbitrary', 'equations', 'allow', 'slowly', 'conditions', 'models', 'results', 'shed', 'light', 'link', 'chaos', 'pointing', 'possible', 'extensions', 'kolmogorov', 'arnold', 'moser', 'kam', 'theorem', 'introduction', 'technological', 'advances', 'synthetic', 'started', 'era', 'non', 'equilibrium', 'isolated', 'matter', 'experimentally', 'probed', 'intrinsic', 'occur', 'featureless', 'thermal', 'scrambling', 'information', 'avoid', 'extensive', 'number', 'integrals', 'localized', 'mbl', 'bethe', 'ansatz', 'integrable', 'host', 'trivial', 'studied', 'require', 'presence', 'quenched', 'disorder', 'fine', 'tuning', 'integrability', 'desirable', 'routes', 'extending', 'coherence', 'progress', 'tied', 'developing', 'complete', 'understanding', 'direction', 'studies', 'considered', 'typical', 'generated', 'applying', 'random', 'operators', 'circuit', 'allowed', 'obtain', 'entanglement', 'physical', 'observables', 'rate', 'experiments', 'revealed', 'significantly', 'complex', 'particular', 'certain']\n"
     ]
    }
   ],
   "source": [
    "items=tfidf.vocabulary_.items()\n",
    "print( [v for v in list(tfidf.vocabulary_.keys())[0:200]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(Config.model):\n",
    "    os.makedirs(Config.model)\n",
    "    \n",
    "with open(Config.tfidf,'wb') as file:\n",
    "    pickle.dump(tfidf,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now start training the logistic regression model let's first check the composition of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "math.SG            250\n",
       "astro-ph           250\n",
       "math.FA            250\n",
       "cs.CY              250\n",
       "stat.ML            250\n",
       "                  ... \n",
       "cs.LO              250\n",
       "math.NT            149\n",
       "physics.hist-ph    119\n",
       "math.KT            119\n",
       "cs.GL               83\n",
       "Name: Category, Length: 147, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('metadata_db','rb') as file:\n",
    "    metadata_db=pickle.load(file)\n",
    "\n",
    "articles=[]\n",
    "categories=[]\n",
    "\n",
    "for article,metadata in metadata_db.items():\n",
    "    articles.append(article)\n",
    "    categories.append(metadata['arxiv_primary_category']['term'])\n",
    "\n",
    "db=pd.DataFrame({'Article':articles,'Category':categories})\n",
    "    \n",
    "db['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes are not too skewed, we can therfore train the model without preoccupying too much of this problem "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_labels_train=[]\n",
    "\n",
    "for article in metadata_db.keys():\n",
    "    article_path=os.path.join(Config.txt_db,article+'.txt')\n",
    "    if os.path.isfile(article_path):\n",
    "        txt_labels_train.append(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The database might contain more articles than the ones in metadata_db, especially if arXivAPI.py was run several times\n",
    "\n",
    "corpus=read_clean(txt_labels_train)\n",
    "X = tfidf.transform(corpus)        \n",
    "y=get_y(txt_labels_train)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save vectorized articles togheter with their names and links for later use\n",
    "articles=[metadata_db[article]['links'][-1]['href'] for article in txt_labels_train]\n",
    "titles=[metadata_db[article]['title'].replace('\\n', '').replace('  ',' ') for article in txt_labels_train]\n",
    "dictionary={'X':X,'articles':np.array(txt_labels_train),'links':np.array(articles),'titles':np.array(titles)}\n",
    "with open(Config.vectorized_articles,'wb') as file:\n",
    "    pickle.dump(dictionary,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all our database it is vectorised, we can perform a classification, based on this vectorised form. As a first attemp we will use a simple logistic regression. In case the model would perform poorely we can take into consideration the use of more sophisticated solutions, like SVM or Random Forest Classifier.\n",
    "\n",
    "In order to have a first rough evaluation of the performances of the model we train it for different values of the regualrization parameter C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ommim/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\r"
     ]
    }
   ],
   "source": [
    "acc_train=[]\n",
    "acc_cval=[]\n",
    "prec_train=[]\n",
    "prec_cval=[]\n",
    "rec_train=[]\n",
    "rec_cval=[]\n",
    "C=[0.1,1,10,100,1000,10000]\n",
    "for c in C:\n",
    "    print(\"{}\\r\".format(c),end=\"\")\n",
    "    logr = LogisticRegression(n_jobs=n_jobs, C=c,random_state=42,solver='lbfgs',penalty='l2',multi_class='multinomial')\n",
    "    logr.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = logr.predict(X_train)\n",
    "    acc_train.append(accuracy_score(y_train,y_pred)*100)\n",
    "    prec_train.append(precision_score(y_train,y_pred,average='weighted')*100)\n",
    "    rec_train.append(recall_score(y_train,y_pred,average='weighted')*100)\n",
    "    \n",
    "    y_pred = logr.predict(X_test)\n",
    "    acc_cval.append(accuracy_score(y_test,y_pred)*100)\n",
    "    prec_cval.append(precision_score(y_test,y_pred,average='weighted')*100)\n",
    "    rec_cval.append(recall_score(y_test,y_pred,average='weighted')*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot the validation curves for the Accuracy, Precision and Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.array(C),100-np.array(acc_train),color='r',label='training')\n",
    "plt.plot(np.array(C),100-np.array(acc_cval),color='b',label='cross validation')\n",
    "plt.title(label='Accuracy Error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.array(C),100-np.array(prec_train),color='r',label='training')\n",
    "plt.plot(np.array(C),100-np.array(prec_cval),color='b',label='cross validation')\n",
    "plt.title(label='Precision Error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.array(C),100-np.array(rec_train),color='r',label='training')\n",
    "plt.plot(np.array(C),100-np.array(rec_cval),color='b',label='cross validation')\n",
    "plt.title(label='Recall Error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58.136519403538024, 66.51847735482079, 68.72279336852829, 69.20440863202741, 69.38038343984441, 68.93581550430675]\n",
      "[62.2480671772894, 66.83098805643054, 68.91370566649377, 69.2816746264161, 69.43035687955678, 68.90729851604877]\n",
      "[58.136519403538024, 66.51847735482079, 68.72279336852829, 69.20440863202741, 69.38038343984441, 68.93581550430675]\n"
     ]
    }
   ],
   "source": [
    "print(acc_cval)\n",
    "print(prec_cval)\n",
    "print(rec_cval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen the model seems to perform better around C=1000 ater this value the model will likeiy suffer of hig-variance (even though we need to go to really large values of C to see that happening). \n",
    "\n",
    "For the purpose of the model it is probably good to have an high precision as we are interested in getting as much actual positive predictions. The data show that there is not much difference between accuracy, recall and precision, this is probably due to the fact that we considered a dataset that is more or less uniform in terms of articles per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='multinomial', n_jobs=8, penalty='l2',\n",
       "                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logr = LogisticRegression(n_jobs=n_jobs, C=1000,random_state=42,solver='lbfgs',penalty='l2',multi_class='multinomial')\n",
    "logr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Config.logr,'wb') as file:\n",
    "    pickle.dump(logr,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now consider the problem of model eavaluation. Let's consider the Accuracy, the Precision and the Recall of the trained model on the cross-validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 69.38038343984441\n",
      "Precision: 69.43035687955678\n",
      "Recall: 69.38038343984441\n"
     ]
    }
   ],
   "source": [
    "y_pred = logr.predict(X_test)\n",
    "acc_cv_1=accuracy_score(y_test,y_pred)*100\n",
    "prec_cv_1=precision_score(y_test,y_pred,average='weighted')*100\n",
    "rec_cv_1=recall_score(y_test,y_pred ,average='weighted')*100\n",
    "\n",
    "print(\"Accuracy: {}\".format(acc_cv_1))\n",
    "print(\"Precision: {}\".format(prec_cv_1))\n",
    "print(\"Recall: {}\".format(rec_cv_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A precision of 70% is definetly not bad, but also not exceedingly good. Given the type of problem that we are trying to solve though, we can probably conclude that this type of evaluation might be too naive. The classification of scientific articles, especially when considering such a larg number of classes, admits a certain degree of ambiuity. For example, a paper that talks about topological effects in p-wave superconductors, can be considered as talking about superconductivity, but also, alternatively, about strongly interacting systems. The category which best describe the paper is therefore, most of time, a matter of tastes of the author. We can therefore try to explore different ways to evaluate the model, which migth perform better than we think.\n",
    "\n",
    "A first attempt  in this direction would be to consider if the algorithm can correctly pick up the general subject of the article. To understand the piece of code below we should consider that given a certain class, arXiv separates with a dot the general subject of from the specific one. For example \"math.GR\" is the category for Group Theory, which is a math subject; \"astro-ph.CO\" is about Cosmology, which is an astro-phisics subject and so on. This type of approach could be still refined as some classes do not follow this pattern; for example quant-ph is the class for Quantum Physics, which arXiv keeps separated from the classes physics.* , but let's not consider this for the moment, as it might be good enough to keep things simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8744095582106141\n",
      "Precision: 0.8741224476888958\n",
      "Recall: 0.8744095582106141\n"
     ]
    }
   ],
   "source": [
    "#Remove whatever comes after the dot, if any, in the classes \n",
    "y_test_strip=[x[:x.rfind('.')] if x.rfind('.')!=-1 else x for x in y_test]\n",
    "y_pred=logr.predict(X_test)\n",
    "y_pred_strip=[x[:x.rfind('.')] if x.rfind('.')!=-1 else x for x in y_pred]\n",
    "print(\"Accuracy: {}\".format(accuracy_score(y_true=y_test_strip,y_pred=y_pred_strip)))\n",
    "print(\"Precision: {}\".format(precision_score(y_true=y_test_strip,y_pred=y_pred_strip,average='weighted')))\n",
    "print(\"Recall: {}\".format(recall_score(y_true=y_test_strip,y_pred=y_pred_strip,average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen the Accuracy of the model made a huge jump. This shows that our model is getting most of the articles subjects correctly and that probably the real accuracy of the model is higher than what we thought. In order to get a better estimate of how good is our model it is probably good to take a step back and to consider what problem that we are trying to solve. We want an application that would return the three best classes that classify a given article, as arXiv allow the author to specify up to three classes for a paper. We can therefore take this into account and consider the classification succesful whenever the training label is one of the best three predicted classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(X,model): \n",
    "    probs=model.predict_proba(X)\n",
    "    for prob in probs: \n",
    "        pos=np.argsort(-prob)\n",
    "        yield model.classes_[pos[:3]]\n",
    "\n",
    "def best_of_3(y_pred,y):\n",
    "    y_best_3=[]\n",
    "    for i,clss in enumerate(y_pred):\n",
    "        if y[i] in clss :\n",
    "            y_best_3.append(y[i])\n",
    "        else:\n",
    "            y_best_3.append(clss[0])\n",
    "    return y_best_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_3=predict_class(X_test,logr)\n",
    "y_pred_best3=best_of_3(y_pred_3,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9103454663332408\n",
      "Precision: 0.9114968701148863\n",
      "Recall: 0.9103454663332408\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {}\".format(accuracy_score(y_true=y_test,y_pred=y_pred_best3)))\n",
    "print(\"Precision: {}\".format(precision_score(y_true=y_test,y_pred=y_pred_best3,average='weighted')))\n",
    "print(\"Recall: {}\".format(recall_score(y_true=y_test,y_pred=y_pred_best3,average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These values are really encouraging and suggest that an hypotetical user of the application would be most likely able to get useful suggestions out of the three classes provided by it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
